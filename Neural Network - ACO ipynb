{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'Bank_Personal_Loan_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_index = df[df['Income']>160].index\n",
    "df = df.drop(inc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Securities Account', 'CD Account', 'Online',\n",
       "       'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = df.drop(['Personal Loan'],axis=1)\n",
    "df_input.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 12)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(df_input.values,df['Personal Loan'].values,test_size=0.25,random_state=46,stratify=df['Personal Loan'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, activation='relu',name='firstlayer'),\n",
    "  tf.keras.layers.Dense(1,activation='sigmoid',name='secondlayer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5057175528873642"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lc = LabelEncoder()\n",
    "ini_pred  =lc.fit_transform(output.numpy().flatten()>0.5) \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_train,ini_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3269614 , -0.20709968,  0.37628734, -0.3448913 , -0.16694307,\n",
       "        -0.0599997 , -0.09584832,  0.27113104, -0.02902627, -0.16968572,\n",
       "        -0.20185542, -0.48541665],\n",
       "       [ 0.09215271, -0.05537713, -0.4100784 , -0.47215867,  0.48129869,\n",
       "        -0.41160822, -0.38137102, -0.13347995,  0.45231366,  0.3897078 ,\n",
       "         0.39112103, -0.17892087],\n",
       "       [-0.22733414, -0.21713257,  0.2085092 , -0.4212011 ,  0.2005744 ,\n",
       "        -0.14055336,  0.14577234,  0.3179009 , -0.09184933,  0.35657895,\n",
       "         0.1954869 ,  0.3224634 ],\n",
       "       [-0.37975287,  0.04749346,  0.0438844 , -0.2059393 , -0.4094528 ,\n",
       "         0.06294298, -0.1603409 , -0.24409378, -0.38569486, -0.46779168,\n",
       "         0.11725342, -0.40268457],\n",
       "       [ 0.42787826,  0.02543592, -0.40395355,  0.05032039,  0.02315283,\n",
       "         0.16491187,  0.17492712,  0.35949147,  0.00426483,  0.04455614,\n",
       "        -0.2268728 , -0.186257  ],\n",
       "       [-0.4491098 , -0.08245385, -0.2703668 ,  0.04163313,  0.28712368,\n",
       "        -0.3266605 , -0.15518856, -0.29952705, -0.3794384 , -0.4101169 ,\n",
       "        -0.12208009, -0.2851957 ],\n",
       "       [-0.11179566, -0.2991246 , -0.07477355,  0.47317135, -0.08118534,\n",
       "        -0.38196254, -0.4576602 ,  0.4190941 ,  0.31805503,  0.10408199,\n",
       "        -0.02532196, -0.10409153],\n",
       "       [-0.14043152,  0.35526538,  0.17907786,  0.45562506, -0.04861462,\n",
       "         0.31128192,  0.3592143 , -0.06339228,  0.15710378, -0.28523576,\n",
       "        -0.20947433,  0.39172745],\n",
       "       [-0.12704396,  0.23805356,  0.27019632,  0.4722644 , -0.34068418,\n",
       "        -0.11330318, -0.38668954, -0.1085037 ,  0.1385119 , -0.3363124 ,\n",
       "        -0.34751236,  0.29442918],\n",
       "       [ 0.08259499,  0.11535156,  0.01471734,  0.04301035,  0.27433562,\n",
       "         0.07736623, -0.17063773,  0.35715342,  0.12840211,  0.0314548 ,\n",
       "        -0.38224018, -0.4003806 ],\n",
       "       [-0.12208343, -0.24423087,  0.17983031, -0.4028263 ,  0.08757997,\n",
       "         0.4918164 , -0.31993294,  0.21543479, -0.26369274,  0.06818509,\n",
       "        -0.17543149,  0.31500638],\n",
       "       [ 0.31523085, -0.17933321, -0.15962386,  0.18097818,  0.16498005,\n",
       "        -0.18318939,  0.10334265, -0.41475284,  0.22926676,  0.43076384,\n",
       "        -0.22331464, -0.4563018 ]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " firstlayer (Dense)          (3498, 12)                156       \n",
      "                                                                 \n",
      " secondlayer (Dense)         (3498, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_lin_weights_nn_weights(weights):\n",
    "    we_list=[]\n",
    "    w1=np.array(weights[:144])\n",
    "    w1=w1.reshape(12,12)\n",
    "    b1=np.array(weights[144:156])\n",
    "    w2=np.array(weights[156:168])\n",
    "    w2=w2.reshape(12,1)\n",
    "    b2=np.array(weights[168:])\n",
    "    b2=b2.reshape(1)\n",
    "    we_list.append(w1)\n",
    "    we_list.append(b1)\n",
    "    we_list.append(w2)\n",
    "    we_list.append(b2)\n",
    "\n",
    "    return we_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(weights,nn):\n",
    "    we=conv_lin_weights_nn_weights(weights)\n",
    "    nn.set_weights(we)\n",
    "    y_pred = nn.predict(X_train)\n",
    "    y_pred = lc.fit_transform(y_pred.flatten() > 0.5)\n",
    "    print('accuracy:',round(accuracy_score(y_pred,Y_train),5)*100)\n",
    "    return accuracy_score(Y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ACO:\n",
    "    def __init__(self, num_ants, num_iterations, num_weights, Q, rho, alpha, beta,model):\n",
    "        self.num_ants = num_ants\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_weights = num_weights\n",
    "        self.Q = Q\n",
    "        self.rho = rho\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.pheromones = np.ones((self.num_weights,)) / self.num_weights\n",
    "        self.best_weights = None\n",
    "        self.best_fitness = np.inf\n",
    "        self.model=model\n",
    "        self.max_weights=None\n",
    "        self.max_fitness=0.0\n",
    "\n",
    "    def _softmax(self, x):\n",
    "        return np.exp(x - np.max(x)) / np.sum(np.exp(x - np.max(x)))\n",
    "\n",
    "    def _compute_probabilities(self, weights):\n",
    "        logits = np.dot(weights, self.pheromones)\n",
    "        probabilities = self._softmax(logits)\n",
    "        return probabilities\n",
    "\n",
    "    def _sample_ant(self, weights):\n",
    "        probabilities = self._compute_probabilities(weights)\n",
    "        ant = np.random.choice(self.num_weights, size=1, p=probabilities)[0]\n",
    "        return ant\n",
    "\n",
    "    def _update_pheromones(self, weights, fitnesses):\n",
    "        for i in range(self.num_weights):\n",
    "            delta = 0.0\n",
    "            for ant in range(self.num_ants):\n",
    "                if fitnesses[ant] <  self.best_fitness:\n",
    "                    self.best_weights = weights[ant]\n",
    "                    self.best_fitness = fitnesses[ant]\n",
    "                if i in weights[ant]:\n",
    "                    delta += self.Q / fitnesses[ant]\n",
    "            self.pheromones[i] = (1 - self.rho) * self.pheromones[i] + delta\n",
    "\n",
    "    def optimize_weights(self, fitness_function):\n",
    "        weights = np.random.uniform(-1, 1, size=(self.num_ants, self.num_weights))\n",
    "        for iteration in range(self.num_iterations):\n",
    "            print('iter ',iteration)\n",
    "\n",
    "            fitnesses=[]\n",
    "            for w in weights:\n",
    "                fit=fitness_function(w,self.model)\n",
    "                if fit >= self.max_fitness:\n",
    "                    self.max_fitness=fit\n",
    "                    self.max_weights=w\n",
    "                fitnesses.append(fit)\n",
    "\n",
    "            self._update_pheromones(weights, fitnesses)\n",
    "            for ant in range(self.num_ants):\n",
    "                print('ant',ant)\n",
    "                ant_weights = weights[ant].copy()\n",
    "                for weight_idx in range(self.num_weights):\n",
    "                    if np.random.rand() < self.alpha:\n",
    "                        ant_weights[weight_idx] += self.beta * np.random.normal()\n",
    "                    else:\n",
    "                        ant_weights[weight_idx] = self.best_weights[weight_idx]\n",
    "                weights[ant] = ant_weights\n",
    "\n",
    "        return self.max_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  0\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 78.473\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 42.367\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 90.70899999999999\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 39.28\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 55.889\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 84.36200000000001\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 37.907000000000004\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 82.018\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  1\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 82.161\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 47.799\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 87.764\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 50.858000000000004\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 51.658\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 88.107\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 34.019\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 68.839\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  2\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 70.497\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 49.057\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 87.107\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 44.768\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 34.677\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 71.527\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 31.561\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 78.616\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  3\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 11.806999999999999\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 62.263999999999996\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 91.109\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 40.137\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 17.124\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 40.794999999999995\n",
      "110/110 [==============================] - 1s 4ms/step\n",
      "accuracy: 26.844\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 75.27199999999999\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  4\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 13.522\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 71.584\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 83.905\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 26.844\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 38.279\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 38.165\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 13.178999999999998\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 75.157\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  5\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 11.006\n",
      "110/110 [==============================] - 1s 4ms/step\n",
      "accuracy: 75.01400000000001\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 73.01299999999999\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 15.866\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 33.961999999999996\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 32.533\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 9.949\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 65.12299999999999\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  6\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 13.007\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 65.12299999999999\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 50.114000000000004\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 12.950000000000001\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 23.871000000000002\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 34.991\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 12.436\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 53.086999999999996\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  7\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 11.777999999999999\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 34.906\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 63.751000000000005\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 11.892999999999999\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 24.071\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 37.763999999999996\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 12.235999999999999\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 46.141\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  8\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 16.81\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 61.063\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 65.323\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 12.864\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 30.932\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 36.964000000000006\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 12.35\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 47.455999999999996\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  9\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 18.811\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 52.629999999999995\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 68.325\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 11.721\n",
      "110/110 [==============================] - 0s 1ms/step\n",
      "accuracy: 47.113\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 39.48\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 11.75\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 41.91\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  10\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 10.406\n",
      "110/110 [==============================] - 1s 5ms/step\n",
      "accuracy: 48.228\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 68.096\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 15.037\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 40.652\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 38.622\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 10.034\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 55.031\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  11\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 20.726\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 51.229\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 66.038\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 15.838\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 24.871\n",
      "110/110 [==============================] - 1s 5ms/step\n",
      "accuracy: 40.166000000000004\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 9.719999999999999\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 59.434\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  12\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 20.125999999999998\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 43.025000000000006\n",
      "110/110 [==============================] - 1s 5ms/step\n",
      "accuracy: 62.407000000000004\n",
      "110/110 [==============================] - 1s 4ms/step\n",
      "accuracy: 15.123000000000001\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 19.154\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 40.194\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 9.92\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 40.109\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  13\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 15.58\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 36.678\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 61.893\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 16.495\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 25.7\n",
      "110/110 [==============================] - 1s 5ms/step\n",
      "accuracy: 32.619\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 8.891\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 40.595\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n",
      "iter  14\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 13.492999999999999\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 36.164\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 53.116\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 11.464\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 25.843\n",
      "110/110 [==============================] - 0s 4ms/step\n",
      "accuracy: 28.531000000000002\n",
      "110/110 [==============================] - 0s 3ms/step\n",
      "accuracy: 7.919\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "accuracy: 30.017\n",
      "ant 0\n",
      "ant 1\n",
      "ant 2\n",
      "ant 3\n",
      "ant 4\n",
      "ant 5\n",
      "ant 6\n",
      "ant 7\n"
     ]
    }
   ],
   "source": [
    "num_ants = 8\n",
    "num_iterations = 15\n",
    "num_weights = 169\n",
    "Q = 0.8\n",
    "rho = 0.5\n",
    "alpha = 0.9\n",
    "beta = 0.1\n",
    "aco = ACO(num_ants, num_iterations, num_weights, Q, rho, alpha, beta,model)\n",
    "\n",
    "bw = aco.optimize_weights(objective_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step\n",
      "testcase accuracy: 31.276778063410454\n"
     ]
    }
   ],
   "source": [
    "se = conv_lin_weights_nn_weights(bw)\n",
    "model.set_weights(se)\n",
    "y_t=model.predict(X_test)\n",
    "Y_t= lc.fit_transform(y_t.flatten() > 0.5)\n",
    "print('testcase accuracy:',accuracy_score(Y_test,Y_t)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
